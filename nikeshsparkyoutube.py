# -*- coding: utf-8 -*-
"""nikeshSparkYoutube.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xYae9B5L_UDZmPWK2IsrEozMmBJZh94A
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz
!tar xf spark-3.1.1-bin-hadoop3.2.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop3.2"

# create a spark session for youtube data
import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()
# Property used to format output tables better
spark.conf.set("spark.sql.repl.eagerEval.enabled", True)
spark

from google.colab import drive
drive.mount('./gdrive')

from google.colab import drive
drive.mount('/content/drive')

!ls "/content/gdrive/MyDrive/pySpark"

!ls "/content/drive/MyDrive/pySpark"

!cp /content/drive/MyDrive/Nikesh_Web_Clawer /content -r

# Load the csv into the dataframe
youtube_df = spark.read.csv("/content/drive/MyDrive/pySpark/Global_YouTube_Statistics.csv", header=True,  inferSchema=True)
youtube_df

youtube_df.printSchema()

# data cleaning
# fillna() is used to replace null value with any 0 value
youtube_df.fillna(value=0).show()

# changing the title from rank to Ranking
youtube_df = youtube_df.withColumnRenamed("rank", "Ranking")
youtube_df.show()

# Dropping all rows with null values on any columns
total_attritions = youtube_df.count()
non_na_attritions = youtube_df.na.drop("all").count()
print("Total rows = ", total_attritions)
print("Total Non-NA rows = ", non_na_attritions)
print("Total NA rows = ", total_attritions - non_na_attritions)
origData = youtube_df.dropna(how='all')

# Dropping duplicate records if any
total_attritions = youtube_df.count()
unique_attritions = youtube_df.dropDuplicates().count()
print("Total rows = ", total_attritions)
print("Total unique rows = ", unique_attritions)
print("Total duplicate rows = ", total_attritions - unique_attritions)

youtube_df.limit(5)

youtube_df.agg({'lowest_yearly_earnings':'avg'})

from pyspark.sql.types import IntegerType
from pyspark.sql.functions import udf

def round_float_down(x):
  return int(x)

round_float_down_udf = udf(round_float_down, IntegerType())

youtube_df.select('Youtuber', 'category', 'Title',
   round_float_down_udf('lowest_yearly_earnings')
  .alias('Lowest early earning')).limit(5)

youtube_df.createOrReplaceTempView("Youtube")

spark.sql('select * from Youtube')

query = """
  SELECT Youtuber, subscribers, country
  FROM Youtube
  WHERE Country == "India"
  ORDER BY subscribers DESC
  LIMIT 10;
"""

spark.sql(query).show()

